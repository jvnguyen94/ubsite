{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Connected to py9 (Python 3.9.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Dataset, download_url, Data,  Batch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "\n",
    "import biographs as bg\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "        raw_file_names = [f for f in os.listdir(\"./d/\") if not f.startswith('.')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A0A5E8G9T8.pdb', 'A0A5E8G9H8.pdb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./d/A0A5E8G9T8.pdb', './d/A0A5E8G9H8.pdb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"./d/\"+f for f in os.listdir(\"./d/\") if not f.startswith('.')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "        raw_file_names = [str(root)+f for f in os.listdir(root) if not f.startswith('.')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./d/A0A5E8G9T8.pdb', './d/A0A5E8G9H8.pdb']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './d/A0A5E8G9T8.pdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if (pathlib.Path(file).suffix == \".pdb\"):\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "#    print(np.allclose(a, a.T, rtol=rtol, atol=atol))\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(ProteinDataset, self).__init__(root, transform=None,\n",
    "                                             pre_transform=None)\n",
    "        self.root = root\n",
    "\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        raw_file_names = [\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')]\n",
    "\n",
    "        data_list = []\n",
    "        count = 0\n",
    "        for file in tqdm(raw_file_names):\n",
    "           if (pathlib.Path(file).suffix == \".pdb\"):\n",
    "\n",
    "               try:\n",
    "                struct = self._get_structure(file)\n",
    "               except:\n",
    "                print(file)\n",
    "                continue\n",
    "               seq = self._get_sequence(struct)\n",
    "               print(seq)\n",
    "\n",
    "          # node features extracted\n",
    "               node_feats = self._get_one_hot_symbftrs(seq)\n",
    "\n",
    "          # edge-index extracted\n",
    "\n",
    "               mat = self._get_adjacency(file)\n",
    "\n",
    "           # if sequence size > matrix dimensions\n",
    "               if (mat.shape[0] < torch.Tensor.size(node_feats)[0]):\n",
    "                 # node_feats = torch.tensor(ftrs.item()[os.path.splitext(os.path.basename(file))[0]])\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'mat size :{mat.shape}')\n",
    "          # create data object\n",
    "\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pt')\n",
    "\n",
    "               elif mat.shape[0] == torch.Tensor.size(node_feats)[0]:\n",
    "                 # node_feats = torch.tensor(ftrs.item()[os.path.splitext(os.path.basename(file))[0]])\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'mat size :{mat.shape}')\n",
    "\n",
    "          # create data object\n",
    "\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pt')\n",
    "\n",
    "        self.data_prot = data_list\n",
    "        print(count)\n",
    "\n",
    "        # data, slices = self.collate(data_list)\n",
    "        # torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    # file stands for file path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.data_prot[idx]\n",
    "\n",
    "    def _get_adjacency(self, file):\n",
    "        edge_ind = []\n",
    "        molecule = bg.Pmolecule(file)\n",
    "        network = molecule.network()\n",
    "        mat = nx.adjacency_matrix(network)\n",
    "        m = mat.todense()\n",
    "        return m\n",
    "\n",
    "    # get adjacency matrix in coo format to pass in GCNN model\n",
    "\n",
    "    def _get_edgeindex(self, file, adjacency_mat):\n",
    "        edge_ind = []\n",
    "        m = self._get_adjacency(file)\n",
    "        # check_symmetric(m, rtol=1e-05, atol=1e-08)\n",
    "\n",
    "        a = np.nonzero(m > 0)[0]\n",
    "        b = np.nonzero(m > 0)[1]\n",
    "        edge_ind.append(a)\n",
    "        edge_ind.append(b)\n",
    "        return torch.tensor(np.array(edge_ind), dtype=torch.long)\n",
    "\n",
    "    # get structure from a pdb file\n",
    "    # Uses biopython\n",
    "\n",
    "    def _get_structure(self, file):\n",
    "        \"\"\"\"\n",
    "        Gets protein structure from PDB\n",
    "        input: PDB filename (i.e.: \"A0A5E8G9T8.pdb\")\n",
    "        output: PDB structure object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(id, file)\n",
    "        return structure\n",
    "\n",
    "    # Function to get sequence from pdb structure\n",
    "    # Uses structure made using biopython\n",
    "    # Those residues for which symbols are U / X are converted into A\n",
    "\n",
    "    def _get_sequence(self, structure):\n",
    "        sequence = \"\"\n",
    "        for model in structure:\n",
    "          for chain in model:\n",
    "            for residue in chain:\n",
    "              if residue.get_resname() in ressymbl.keys():\n",
    "                  sequence = sequence + ressymbl[residue.get_resname()]\n",
    "        return sequence\n",
    "\n",
    "    # One hot encoding for symbols\n",
    "\n",
    "    def _get_one_hot_symbftrs(self, sequence):\n",
    "        one_hot_symb = np.zeros((len(sequence), len(pro_res_table)))\n",
    "        row = 0\n",
    "        for res in sequence:\n",
    "          col = pro_res_table.index(res)\n",
    "          one_hot_symb[row][col] = 1\n",
    "          row += 1\n",
    "        return torch.tensor(one_hot_symb, dtype=torch.float)\n",
    "\n",
    "    # Residue features calculated from pcp_dict\n",
    "\n",
    "    def _get_res_ftrs(self, sequence):\n",
    "        res_ftrs_out = []\n",
    "        for res in sequence:\n",
    "          res_ftrs_out.append(pcp_dict[res])\n",
    "        res_ftrs_out = np.array(res_ftrs_out)\n",
    "        # print(res_ftrs_out.shape)\n",
    "        return torch.tensor(res_ftrs_out, dtype=torch.float)\n",
    "\n",
    "    # total features after concatenating one_hot_symbftrs and res_ftrs\n",
    "\n",
    "    def _get_node_ftrs(self, sequence):\n",
    "        one_hot_symb = one_hot_symbftrs(sequence)\n",
    "        res_ftrs_out = res_ftrs(sequence)\n",
    "        return torch.tensor(np.hstack((one_hot_symb, res_ftrs_out)), dtype=torch.float)\n",
    "\n",
    "\n",
    "#prot_graphs = ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "#    print(np.allclose(a, a.T, rtol=rtol, atol=atol))\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "         self.root = root\n",
    "\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        raw_file_names = [\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')]\n",
    "\n",
    "        data_list = []\n",
    "        count = 0\n",
    "        for file in tqdm(raw_file_names):\n",
    "           if (pathlib.Path(file).suffix == \".pdb\"):\n",
    "\n",
    "               try:\n",
    "                struct = self._get_structure(file)\n",
    "               except:\n",
    "                print(file)\n",
    "                continue\n",
    "               seq = self._get_sequence(struct)\n",
    "               print(seq)\n",
    "\n",
    "          # node features extracted\n",
    "               node_feats = self._get_one_hot_symbftrs(seq)\n",
    "\n",
    "          # edge-index extracted\n",
    "\n",
    "               mat = self._get_adjacency(file)\n",
    "\n",
    "           # if sequence size > matrix dimensions\n",
    "               if (mat.shape[0] < torch.Tensor.size(node_feats)[0]):\n",
    "                 # node_feats = torch.tensor(ftrs.item()[os.path.splitext(os.path.basename(file))[0]])\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'mat size :{mat.shape}')\n",
    "          # create data object\n",
    "\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pt')\n",
    "\n",
    "               elif mat.shape[0] == torch.Tensor.size(node_feats)[0]:\n",
    "                 # node_feats = torch.tensor(ftrs.item()[os.path.splitext(os.path.basename(file))[0]])\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'mat size :{mat.shape}')\n",
    "\n",
    "          # create data object\n",
    "\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pt')\n",
    "\n",
    "        self.data_prot = data_list\n",
    "        print(count)\n",
    "\n",
    "        # data, slices = self.collate(data_list)\n",
    "        # torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    # file stands for file path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.data_prot[idx]\n",
    "\n",
    "    def _get_adjacency(self, file):\n",
    "        edge_ind = []\n",
    "        molecule = bg.Pmolecule(file)\n",
    "        network = molecule.network()\n",
    "        mat = nx.adjacency_matrix(network)\n",
    "        m = mat.todense()\n",
    "        return m\n",
    "\n",
    "    # get adjacency matrix in coo format to pass in GCNN model\n",
    "\n",
    "    def _get_edgeindex(self, file, adjacency_mat):\n",
    "        edge_ind = []\n",
    "        m = self._get_adjacency(file)\n",
    "        # check_symmetric(m, rtol=1e-05, atol=1e-08)\n",
    "\n",
    "        a = np.nonzero(m > 0)[0]\n",
    "        b = np.nonzero(m > 0)[1]\n",
    "        edge_ind.append(a)\n",
    "        edge_ind.append(b)\n",
    "        return torch.tensor(np.array(edge_ind), dtype=torch.long)\n",
    "\n",
    "    # get structure from a pdb file\n",
    "    # Uses biopython\n",
    "\n",
    "    def _get_structure(self, file):\n",
    "        \"\"\"\"\n",
    "        Gets protein structure from PDB\n",
    "        input: PDB filename (i.e.: \"A0A5E8G9T8.pdb\")\n",
    "        output: PDB structure object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(id, file)\n",
    "        return structure\n",
    "\n",
    "    # Function to get sequence from pdb structure\n",
    "    # Uses structure made using biopython\n",
    "    # Those residues for which symbols are U / X are converted into A\n",
    "\n",
    "    def _get_sequence(self, structure):\n",
    "        sequence = \"\"\n",
    "        for model in structure:\n",
    "          for chain in model:\n",
    "            for residue in chain:\n",
    "              if residue.get_resname() in ressymbl.keys():\n",
    "                  sequence = sequence + ressymbl[residue.get_resname()]\n",
    "        return sequence\n",
    "\n",
    "    # One hot encoding for symbols\n",
    "\n",
    "    def _get_one_hot_symbftrs(self, sequence):\n",
    "        one_hot_symb = np.zeros((len(sequence), len(pro_res_table)))\n",
    "        row = 0\n",
    "        for res in sequence:\n",
    "          col = pro_res_table.index(res)\n",
    "          one_hot_symb[row][col] = 1\n",
    "          row += 1\n",
    "        return torch.tensor(one_hot_symb, dtype=torch.float)\n",
    "\n",
    "    # Residue features calculated from pcp_dict\n",
    "\n",
    "    def _get_res_ftrs(self, sequence):\n",
    "        res_ftrs_out = []\n",
    "        for res in sequence:\n",
    "          res_ftrs_out.append(pcp_dict[res])\n",
    "        res_ftrs_out = np.array(res_ftrs_out)\n",
    "        # print(res_ftrs_out.shape)\n",
    "        return torch.tensor(res_ftrs_out, dtype=torch.float)\n",
    "\n",
    "    # total features after concatenating one_hot_symbftrs and res_ftrs\n",
    "\n",
    "    def _get_node_ftrs(self, sequence):\n",
    "        one_hot_symb = one_hot_symbftrs(sequence)\n",
    "        res_ftrs_out = res_ftrs(sequence)\n",
    "        return torch.tensor(np.hstack((one_hot_symb, res_ftrs_out)), dtype=torch.float)\n",
    "\n",
    "\n",
    "#prot_graphs = ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_graphs = ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_download',\n",
       " '_get_adjacency',\n",
       " '_get_edgeindex',\n",
       " '_get_node_ftrs',\n",
       " '_get_one_hot_symbftrs',\n",
       " '_get_res_ftrs',\n",
       " '_get_sequence',\n",
       " '_get_structure',\n",
       " '_infer_num_classes',\n",
       " '_is_protocol',\n",
       " '_process',\n",
       " 'download',\n",
       " 'get',\n",
       " 'get_summary',\n",
       " 'has_download',\n",
       " 'has_process',\n",
       " 'index_select',\n",
       " 'indices',\n",
       " 'len',\n",
       " 'num_classes',\n",
       " 'num_edge_features',\n",
       " 'num_features',\n",
       " 'num_node_features',\n",
       " 'print_summary',\n",
       " 'process',\n",
       " 'processed_dir',\n",
       " 'processed_file_names',\n",
       " 'processed_paths',\n",
       " 'raw_dir',\n",
       " 'raw_file_names',\n",
       " 'raw_paths',\n",
       " 'root',\n",
       " 'shuffle',\n",
       " 'to_datapipe']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(prot_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-769c62593c4e>\", line 1, in <module>\n",
      "    prot_graphs.raw_paths\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/torch_geometric/data/dataset.py\", line 200, in raw_paths\n",
      "    files = self.raw_file_names\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/torch_geometric/data/dataset.py\", line 64, in raw_file_names\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1005, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "prot_graphs.raw_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_graphs.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "#    print(np.allclose(a, a.T, rtol=rtol, atol=atol))\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "         self.root = root\n",
    "\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        raw_file_names = [\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')]\n",
    "\n",
    "        data_list = []\n",
    "        count = 0\n",
    "        for file in tqdm(raw_file_names):\n",
    "           if (pathlib.Path(file).suffix == \".pdb\"):\n",
    "\n",
    "               try:\n",
    "                struct = self._get_structure(file)\n",
    "               except:\n",
    "                print(file)\n",
    "                continue\n",
    "               seq = self._get_sequence(struct)\n",
    "               print(seq)\n",
    "\n",
    "          # node features extracted\n",
    "               node_feats = self._get_one_hot_symbftrs(seq)\n",
    "\n",
    "          # edge-index extracted\n",
    "\n",
    "               mat = self._get_adjacency(file)\n",
    "\n",
    "           # if sequence size > matrix dimensions\n",
    "               if (mat.shape[0] < torch.Tensor.size(node_feats)[0]):\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'Mat size :{mat.shape}')\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pt')\n",
    "\n",
    "               elif mat.shape[0] == torch.Tensor.size(node_feats)[0]:\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'mat size :{mat.shape}')\n",
    "\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pdb')\n",
    "\n",
    "        self.data_prot = data_list\n",
    "        print(count)\n",
    "\n",
    "        # data, slices = self.collate(data_list)\n",
    "        # torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    # file stands for file path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.data_prot[idx]\n",
    "\n",
    "    def _get_adjacency(self, file):\n",
    "        edge_ind = []\n",
    "        molecule = bg.Pmolecule(file)\n",
    "        network = molecule.network()\n",
    "        mat = nx.adjacency_matrix(network)\n",
    "        m = mat.todense()\n",
    "        return m\n",
    "\n",
    "    # get adjacency matrix in coo format to pass in GCNN model\n",
    "\n",
    "    def _get_edgeindex(self, file, adjacency_mat):\n",
    "        edge_ind = []\n",
    "        m = self._get_adjacency(file)\n",
    "        # check_symmetric(m, rtol=1e-05, atol=1e-08)\n",
    "\n",
    "        a = np.nonzero(m > 0)[0]\n",
    "        b = np.nonzero(m > 0)[1]\n",
    "        edge_ind.append(a)\n",
    "        edge_ind.append(b)\n",
    "        return torch.tensor(np.array(edge_ind), dtype=torch.long)\n",
    "\n",
    "    # get structure from a pdb file\n",
    "    # Uses biopython\n",
    "\n",
    "    def _get_structure(self, file):\n",
    "        \"\"\"\"\n",
    "        Gets protein structure from PDB\n",
    "        input: PDB filename (i.e.: \"A0A5E8G9T8.pdb\")\n",
    "        output: PDB structure object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(id, file)\n",
    "        return structure\n",
    "\n",
    "    # Function to get sequence from pdb structure\n",
    "    # Uses structure made using biopython\n",
    "    # Those residues for which symbols are U / X are converted into A\n",
    "\n",
    "    def _get_sequence(self, structure):\n",
    "        sequence = \"\"\n",
    "        for model in structure:\n",
    "          for chain in model:\n",
    "            for residue in chain:\n",
    "              if residue.get_resname() in ressymbl.keys():\n",
    "                  sequence = sequence + ressymbl[residue.get_resname()]\n",
    "        return sequence\n",
    "\n",
    "    # One hot encoding for symbols\n",
    "\n",
    "    def _get_one_hot_symbftrs(self, sequence):\n",
    "        one_hot_symb = np.zeros((len(sequence), len(pro_res_table)))\n",
    "        row = 0\n",
    "        for res in sequence:\n",
    "          col = pro_res_table.index(res)\n",
    "          one_hot_symb[row][col] = 1\n",
    "          row += 1\n",
    "        return torch.tensor(one_hot_symb, dtype=torch.float)\n",
    "\n",
    "    # Residue features calculated from pcp_dict\n",
    "\n",
    "    def _get_res_ftrs(self, sequence):\n",
    "        res_ftrs_out = []\n",
    "        for res in sequence:\n",
    "          res_ftrs_out.append(pcp_dict[res])\n",
    "        res_ftrs_out = np.array(res_ftrs_out)\n",
    "        # print(res_ftrs_out.shape)\n",
    "        return torch.tensor(res_ftrs_out, dtype=torch.float)\n",
    "\n",
    "    # total features after concatenating one_hot_symbftrs and res_ftrs\n",
    "\n",
    "    def _get_node_ftrs(self, sequence):\n",
    "        one_hot_symb = one_hot_symbftrs(sequence)\n",
    "        res_ftrs_out = res_ftrs(sequence)\n",
    "        return torch.tensor(np.hstack((one_hot_symb, res_ftrs_out)), dtype=torch.float)\n",
    "\n",
    "\n",
    "#prot_graphs = ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_graphs = ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.ProteinDataset"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prot_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root': './d/'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(prot_graphs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root': './d/'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(prot_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "#    print(np.allclose(a, a.T, rtol=rtol, atol=atol))\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "         self.root = root\n",
    "\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        raw_file_names = [\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')]\n",
    "\n",
    "        data_list = []\n",
    "        count = 0\n",
    "        for file in tqdm(raw_file_names):\n",
    "           if (pathlib.Path(file).suffix == \".pdb\"):\n",
    "\n",
    "               try:\n",
    "                struct = self._get_structure(file)\n",
    "               except:\n",
    "                print(file)\n",
    "                continue\n",
    "               seq = self._get_sequence(struct)\n",
    "               print(seq)\n",
    "\n",
    "          # node features extracted\n",
    "               node_feats = self._get_one_hot_symbftrs(seq)\n",
    "\n",
    "          # edge-index extracted\n",
    "\n",
    "               mat = self._get_adjacency(file)\n",
    "\n",
    "           # if sequence size > matrix dimensions\n",
    "               if (mat.shape[0] < torch.Tensor.size(node_feats)[0]):\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'Mat size :{mat.shape}')\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pt')\n",
    "\n",
    "               elif mat.shape[0] == torch.Tensor.size(node_feats)[0]:\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'mat size :{mat.shape}')\n",
    "\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pdb')\n",
    "\n",
    "        self.data_prot = data_list\n",
    "        print(count)\n",
    "\n",
    "        # data, slices = self.collate(data_list)\n",
    "        # torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len([\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')])\n",
    "\n",
    "    # file stands for file path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.data_prot[idx]\n",
    "\n",
    "    def _get_adjacency(self, file):\n",
    "        edge_ind = []\n",
    "        molecule = bg.Pmolecule(file)\n",
    "        network = molecule.network()\n",
    "        mat = nx.adjacency_matrix(network)\n",
    "        m = mat.todense()\n",
    "        return m\n",
    "\n",
    "    # get adjacency matrix in coo format to pass in GCNN model\n",
    "\n",
    "    def _get_edgeindex(self, file, adjacency_mat):\n",
    "        edge_ind = []\n",
    "        m = self._get_adjacency(file)\n",
    "        # check_symmetric(m, rtol=1e-05, atol=1e-08)\n",
    "\n",
    "        a = np.nonzero(m > 0)[0]\n",
    "        b = np.nonzero(m > 0)[1]\n",
    "        edge_ind.append(a)\n",
    "        edge_ind.append(b)\n",
    "        return torch.tensor(np.array(edge_ind), dtype=torch.long)\n",
    "\n",
    "    # get structure from a pdb file\n",
    "    # Uses biopython\n",
    "\n",
    "    def _get_structure(self, file):\n",
    "        \"\"\"\"\n",
    "        Gets protein structure from PDB\n",
    "        input: PDB filename (i.e.: \"A0A5E8G9T8.pdb\")\n",
    "        output: PDB structure object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(id, file)\n",
    "        return structure\n",
    "\n",
    "    # Function to get sequence from pdb structure\n",
    "    # Uses structure made using biopython\n",
    "    # Those residues for which symbols are U / X are converted into A\n",
    "\n",
    "    def _get_sequence(self, structure):\n",
    "        sequence = \"\"\n",
    "        for model in structure:\n",
    "          for chain in model:\n",
    "            for residue in chain:\n",
    "              if residue.get_resname() in ressymbl.keys():\n",
    "                  sequence = sequence + ressymbl[residue.get_resname()]\n",
    "        return sequence\n",
    "\n",
    "    # One hot encoding for symbols\n",
    "\n",
    "    def _get_one_hot_symbftrs(self, sequence):\n",
    "        one_hot_symb = np.zeros((len(sequence), len(pro_res_table)))\n",
    "        row = 0\n",
    "        for res in sequence:\n",
    "          col = pro_res_table.index(res)\n",
    "          one_hot_symb[row][col] = 1\n",
    "          row += 1\n",
    "        return torch.tensor(one_hot_symb, dtype=torch.float)\n",
    "\n",
    "    # Residue features calculated from pcp_dict\n",
    "\n",
    "    def _get_res_ftrs(self, sequence):\n",
    "        res_ftrs_out = []\n",
    "        for res in sequence:\n",
    "          res_ftrs_out.append(pcp_dict[res])\n",
    "        res_ftrs_out = np.array(res_ftrs_out)\n",
    "        # print(res_ftrs_out.shape)\n",
    "        return torch.tensor(res_ftrs_out, dtype=torch.float)\n",
    "\n",
    "    # total features after concatenating one_hot_symbftrs and res_ftrs\n",
    "\n",
    "    def _get_node_ftrs(self, sequence):\n",
    "        one_hot_symb = one_hot_symbftrs(sequence)\n",
    "        res_ftrs_out = res_ftrs(sequence)\n",
    "        return torch.tensor(np.hstack((one_hot_symb, res_ftrs_out)), dtype=torch.float)\n",
    "\n",
    "\n",
    "#prot_graphs = ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteinDataset(2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProteinDataset(2)\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Dataset.len of ProteinDataset(2)>\n"
     ]
    }
   ],
   "source": [
    "print(a.len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProteinDataset(2)\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ProteinDataset(2)]\n"
     ]
    }
   ],
   "source": [
    "print([a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Dataset.len of ProteinDataset(2)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Connected to py9 (Python 3.9.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _get_structure( file):\n",
    "        \"\"\"\"\n",
    "        Gets protein structure from PDB\n",
    "        input: PDB filename (i.e.: \"A0A5E8G9T8.pdb\")\n",
    "        output: PDB structure object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(id, file)\n",
    "        return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-681004296f48>\", line 2, in <module>\n",
      "    str(root)+f for f in os.listdir(root) if not f.startswith('.')]\n",
      "NameError: name 'root' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1005, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "        raw_file_names = [\n",
    "            str(root)+f for f in os.listdir(root) if not f.startswith('.')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "#    print(np.allclose(a, a.T, rtol=rtol, atol=atol))\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "         self.root = root\n",
    "\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        raw_file_names = [\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')]\n",
    "\n",
    "        data_list = []\n",
    "        count = 0\n",
    "        for file in tqdm(raw_file_names):\n",
    "           if (pathlib.Path(file).suffix == \".pdb\"):\n",
    "\n",
    "               try:\n",
    "                struct = self._get_structure(file)\n",
    "               except:\n",
    "                print(file)\n",
    "                \n",
    "    def _get_structure(self, file):\n",
    "        \"\"\"\"\n",
    "        Gets protein structure from PDB\n",
    "        input: PDB filename (i.e.: \"A0A5E8G9T8.pdb\")\n",
    "        output: PDB structure object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(id, file)\n",
    "        return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/formatters.py\", line 223, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/formatters.py\", line 708, in __call__\n",
      "    printer.pretty(obj)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/lib/pretty.py\", line 410, in pretty\n",
      "    return _repr_pprint(obj, self, cycle)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/lib/pretty.py\", line 778, in _repr_pprint\n",
      "    output = repr(obj)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/torch_geometric/data/dataset.py\", line 362, in __repr__\n",
      "    arg_repr = str(len(self)) if len(self) > 1 else ''\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/torch_geometric/data/dataset.py\", line 272, in __len__\n",
      "    return len(self.indices())\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/torch_geometric/data/dataset.py\", line 118, in indices\n",
      "    return range(self.len()) if self._indices is None else self._indices\n",
      "AttributeError: 'ProteinDataset' object has no attribute '_indices'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1005, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, download_url, Data,  Batch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "\n",
    "import biographs as bg\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of 20 proteins\n",
    "pro_res_table = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K',\n",
    "                 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "# Dictionary for getting Residue symbols\n",
    "ressymbl = {'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E', 'PHE': 'F', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I', 'LYS': 'K', 'LEU': 'L',\n",
    "            'MET': 'M', 'ASN': 'N', 'PRO': 'P', 'GLN': 'Q', 'ARG': 'R', 'SER': 'S', 'THR': 'T', 'VAL': 'V', 'TRP': 'W', 'TYR': 'Y'}\n",
    "\n",
    "# residue features stored as key-value pair\n",
    "pcp_dict = {'A': [0.62014, -0.18875, -1.2387, -0.083627, -1.3296, -1.3817, -0.44118],\n",
    "            'C': [0.29007, -0.44041, -0.76847, -1.05, -0.4893, -0.77494, -1.1148],\n",
    "            'D': [-0.9002, 1.5729, -0.89497, 1.7376, -0.72498, -0.50189, -0.91814],\n",
    "            'E': [-0.74017, 1.5729, -0.28998, 1.4774, -0.25361, 0.094051, -0.4471],\n",
    "            'F': [1.1903, -1.1954, 1.1812, -1.1615, 1.1707, 0.8872, 0.02584],\n",
    "            'G': [0.48011, 0.062916, -1.9949, 0.25088, -1.8009, -2.0318, 2.2022],\n",
    "            'H': [-0.40009, -0.18875, 0.17751, 0.77123, 0.5559, 0.44728, -0.71617],\n",
    "            'I': [1.3803, -0.84308, 0.57625, -1.1615, 0.10503, -0.018637, -0.21903],\n",
    "            'K': [-1.5003, 1.5729, 0.75499, 1.1057, 0.44318, 0.95221, -0.27937],\n",
    "            'L': [1.0602, -0.84308, 0.57625, -1.273, 0.10503, 0.24358, 0.24301],\n",
    "            'M': [0.64014, -0.59141, 0.59275, -0.97565, 0.46368, 0.46679, -0.51046],\n",
    "            'N': [-0.78018, 1.0696, -0.38073, 1.2172, -0.42781, -0.35453, -0.46879],\n",
    "            'P': [0.12003, 0.062916, -0.84272, -0.1208, -0.45855, -0.75977, 3.1323],\n",
    "            'Q': [-0.85019, 0.16358, 0.22426, 0.8084, 0.04355, 0.24575, 0.20516],\n",
    "            'R': [-2.5306, 1.5729, 0.89249, 0.8084, 1.181, 1.6067, 0.11866],\n",
    "            'S': [-0.18004, 0.21392, -1.1892, 0.32522, -1.1656, -1.1282, -0.48056],\n",
    "            'T': [-0.050011, -0.13842, -0.58422, 0.10221, -0.69424, -0.63625, -0.50017],\n",
    "            'V': [1.0802, -0.69208, -0.028737, -0.90132, -0.36633, -0.3762, 0.32502],\n",
    "            'W': [0.81018, -1.6484, 2.0062, -1.0872, 2.3901, 1.8299, 0.032377],\n",
    "            'Y': [0.26006, -1.0947, 1.2307, -0.78981, 1.2527, 1.1906, -0.18876]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "#    print(np.allclose(a, a.T, rtol=rtol, atol=atol))\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "         self.root = root\n",
    "\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        raw_file_names = [\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')]\n",
    "\n",
    "        data_list = []\n",
    "        count = 0\n",
    "        for file in tqdm(raw_file_names):\n",
    "           if (pathlib.Path(file).suffix == \".pdb\"):\n",
    "\n",
    "               try:\n",
    "                struct = self._get_structure(file)\n",
    "               except:\n",
    "                print(file)\n",
    "                \n",
    "    def _get_structure(self, file):\n",
    "        \"\"\"\"\n",
    "        Gets protein structure from PDB\n",
    "        input: PDB filename (i.e.: \"A0A5E8G9T8.pdb\")\n",
    "        output: PDB structure object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(id, file)\n",
    "        return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/formatters.py\", line 223, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/formatters.py\", line 708, in __call__\n",
      "    printer.pretty(obj)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/lib/pretty.py\", line 410, in pretty\n",
      "    return _repr_pprint(obj, self, cycle)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/lib/pretty.py\", line 778, in _repr_pprint\n",
      "    output = repr(obj)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/torch_geometric/data/dataset.py\", line 362, in __repr__\n",
      "    arg_repr = str(len(self)) if len(self) > 1 else ''\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/torch_geometric/data/dataset.py\", line 272, in __len__\n",
      "    return len(self.indices())\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/torch_geometric/data/dataset.py\", line 118, in indices\n",
      "    return range(self.len()) if self._indices is None else self._indices\n",
      "AttributeError: 'ProteinDataset' object has no attribute '_indices'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1005, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "#    print(np.allclose(a, a.T, rtol=rtol, atol=atol))\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "         self.root = root\n",
    "\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        raw_file_names = [\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')]\n",
    "\n",
    "        data_list = []\n",
    "        count = 0\n",
    "        for file in tqdm(raw_file_names):\n",
    "           if (pathlib.Path(file).suffix == \".pdb\"):\n",
    "\n",
    "               try:\n",
    "                struct = self._get_structure(file)\n",
    "               except:\n",
    "                print(file)\n",
    "                continue\n",
    "               seq = self._get_sequence(struct)\n",
    "               print(seq)\n",
    "\n",
    "          # node features extracted\n",
    "               node_feats = self._get_one_hot_symbftrs(seq)\n",
    "\n",
    "          # edge-index extracted\n",
    "\n",
    "               mat = self._get_adjacency(file)\n",
    "\n",
    "           # if sequence size > matrix dimensions\n",
    "               if (mat.shape[0] < torch.Tensor.size(node_feats)[0]):\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'Mat size :{mat.shape}')\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pt')\n",
    "\n",
    "               elif mat.shape[0] == torch.Tensor.size(node_feats)[0]:\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'mat size :{mat.shape}')\n",
    "\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pdb')\n",
    "\n",
    "        self.data_prot = data_list\n",
    "        print(count)\n",
    "\n",
    "        # data, slices = self.collate(data_list)\n",
    "        # torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len([\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')])\n",
    "\n",
    "    # file stands for file path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.data_prot[idx]\n",
    "\n",
    "    def _get_adjacency(self, file):\n",
    "        edge_ind = []\n",
    "        molecule = bg.Pmolecule(file)\n",
    "        network = molecule.network()\n",
    "        mat = nx.adjacency_matrix(network)\n",
    "        m = mat.todense()\n",
    "        return m\n",
    "\n",
    "    # get adjacency matrix in coo format to pass in GCNN model\n",
    "\n",
    "    def _get_edgeindex(self, file, adjacency_mat):\n",
    "        edge_ind = []\n",
    "        m = self._get_adjacency(file)\n",
    "        # check_symmetric(m, rtol=1e-05, atol=1e-08)\n",
    "\n",
    "        a = np.nonzero(m > 0)[0]\n",
    "        b = np.nonzero(m > 0)[1]\n",
    "        edge_ind.append(a)\n",
    "        edge_ind.append(b)\n",
    "        return torch.tensor(np.array(edge_ind), dtype=torch.long)\n",
    "\n",
    "    # get structure from a pdb file\n",
    "    # Uses biopython\n",
    "\n",
    "    def _get_structure(self, file):\n",
    "        \"\"\"\"\n",
    "        Gets protein structure from PDB\n",
    "        input: PDB filename (i.e.: \"A0A5E8G9T8.pdb\")\n",
    "        output: PDB structure object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(id, file)\n",
    "        return structure\n",
    "\n",
    "    # Function to get sequence from pdb structure\n",
    "    # Uses structure made using biopython\n",
    "    # Those residues for which symbols are U / X are converted into A\n",
    "\n",
    "    def _get_sequence(self, structure):\n",
    "        sequence = \"\"\n",
    "        for model in structure:\n",
    "          for chain in model:\n",
    "            for residue in chain:\n",
    "              if residue.get_resname() in ressymbl.keys():\n",
    "                  sequence = sequence + ressymbl[residue.get_resname()]\n",
    "        return sequence\n",
    "\n",
    "    # One hot encoding for symbols\n",
    "\n",
    "    def _get_one_hot_symbftrs(self, sequence):\n",
    "        one_hot_symb = np.zeros((len(sequence), len(pro_res_table)))\n",
    "        row = 0\n",
    "        for res in sequence:\n",
    "          col = pro_res_table.index(res)\n",
    "          one_hot_symb[row][col] = 1\n",
    "          row += 1\n",
    "        return torch.tensor(one_hot_symb, dtype=torch.float)\n",
    "\n",
    "    # Residue features calculated from pcp_dict\n",
    "\n",
    "    def _get_res_ftrs(self, sequence):\n",
    "        res_ftrs_out = []\n",
    "        for res in sequence:\n",
    "          res_ftrs_out.append(pcp_dict[res])\n",
    "        res_ftrs_out = np.array(res_ftrs_out)\n",
    "        # print(res_ftrs_out.shape)\n",
    "        return torch.tensor(res_ftrs_out, dtype=torch.float)\n",
    "\n",
    "    # total features after concatenating one_hot_symbftrs and res_ftrs\n",
    "\n",
    "    def _get_node_ftrs(self, sequence):\n",
    "        one_hot_symb = one_hot_symbftrs(sequence)\n",
    "        res_ftrs_out = res_ftrs(sequence)\n",
    "        return torch.tensor(np.hstack((one_hot_symb, res_ftrs_out)), dtype=torch.float)\n",
    "\n",
    "\n",
    "#prot_graphs = ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/formatters.py\", line 223, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/formatters.py\", line 708, in __call__\n",
      "    printer.pretty(obj)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/lib/pretty.py\", line 410, in pretty\n",
      "    return _repr_pprint(obj, self, cycle)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/lib/pretty.py\", line 778, in _repr_pprint\n",
      "    output = repr(obj)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/torch_geometric/data/dataset.py\", line 362, in __repr__\n",
      "    arg_repr = str(len(self)) if len(self) > 1 else ''\n",
      "  File \"<ipython-input-11-ac894b2244f8>\", line 71, in __len__\n",
      "    str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')])\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './d/'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1005, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of 20 proteins\n",
    "pro_res_table = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K',\n",
    "                 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "# Dictionary for getting Residue symbols\n",
    "ressymbl = {'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E', 'PHE': 'F', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I', 'LYS': 'K', 'LEU': 'L',\n",
    "            'MET': 'M', 'ASN': 'N', 'PRO': 'P', 'GLN': 'Q', 'ARG': 'R', 'SER': 'S', 'THR': 'T', 'VAL': 'V', 'TRP': 'W', 'TYR': 'Y'}\n",
    "\n",
    "# residue features stored as key-value pair\n",
    "pcp_dict = {'A': [0.62014, -0.18875, -1.2387, -0.083627, -1.3296, -1.3817, -0.44118],\n",
    "            'C': [0.29007, -0.44041, -0.76847, -1.05, -0.4893, -0.77494, -1.1148],\n",
    "            'D': [-0.9002, 1.5729, -0.89497, 1.7376, -0.72498, -0.50189, -0.91814],\n",
    "            'E': [-0.74017, 1.5729, -0.28998, 1.4774, -0.25361, 0.094051, -0.4471],\n",
    "            'F': [1.1903, -1.1954, 1.1812, -1.1615, 1.1707, 0.8872, 0.02584],\n",
    "            'G': [0.48011, 0.062916, -1.9949, 0.25088, -1.8009, -2.0318, 2.2022],\n",
    "            'H': [-0.40009, -0.18875, 0.17751, 0.77123, 0.5559, 0.44728, -0.71617],\n",
    "            'I': [1.3803, -0.84308, 0.57625, -1.1615, 0.10503, -0.018637, -0.21903],\n",
    "            'K': [-1.5003, 1.5729, 0.75499, 1.1057, 0.44318, 0.95221, -0.27937],\n",
    "            'L': [1.0602, -0.84308, 0.57625, -1.273, 0.10503, 0.24358, 0.24301],\n",
    "            'M': [0.64014, -0.59141, 0.59275, -0.97565, 0.46368, 0.46679, -0.51046],\n",
    "            'N': [-0.78018, 1.0696, -0.38073, 1.2172, -0.42781, -0.35453, -0.46879],\n",
    "            'P': [0.12003, 0.062916, -0.84272, -0.1208, -0.45855, -0.75977, 3.1323],\n",
    "            'Q': [-0.85019, 0.16358, 0.22426, 0.8084, 0.04355, 0.24575, 0.20516],\n",
    "            'R': [-2.5306, 1.5729, 0.89249, 0.8084, 1.181, 1.6067, 0.11866],\n",
    "            'S': [-0.18004, 0.21392, -1.1892, 0.32522, -1.1656, -1.1282, -0.48056],\n",
    "            'T': [-0.050011, -0.13842, -0.58422, 0.10221, -0.69424, -0.63625, -0.50017],\n",
    "            'V': [1.0802, -0.69208, -0.028737, -0.90132, -0.36633, -0.3762, 0.32502],\n",
    "            'W': [0.81018, -1.6484, 2.0062, -1.0872, 2.3901, 1.8299, 0.032377],\n",
    "            'Y': [0.26006, -1.0947, 1.2307, -0.78981, 1.2527, 1.1906, -0.18876]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "#    print(np.allclose(a, a.T, rtol=rtol, atol=atol))\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "         self.root = root\n",
    "\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        raw_file_names = [str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')]\n",
    "\n",
    "        data_list = []\n",
    "        count = 0\n",
    "        for file in tqdm(raw_file_names):\n",
    "           if (pathlib.Path(file).suffix == \".pdb\"):\n",
    "\n",
    "               try:\n",
    "                struct = self._get_structure(file)\n",
    "               except:\n",
    "                print(file)\n",
    "                continue\n",
    "               seq = self._get_sequence(struct)\n",
    "               print(seq)\n",
    "\n",
    "          # node features extracted\n",
    "               node_feats = self._get_one_hot_symbftrs(seq)\n",
    "\n",
    "          # edge-index extracted\n",
    "\n",
    "               mat = self._get_adjacency(file)\n",
    "\n",
    "           # if sequence size > matrix dimensions\n",
    "               if (mat.shape[0] < torch.Tensor.size(node_feats)[0]):\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'Mat size :{mat.shape}')\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pt')\n",
    "\n",
    "               elif mat.shape[0] == torch.Tensor.size(node_feats)[0]:\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'mat size :{mat.shape}')\n",
    "\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pdb')\n",
    "\n",
    "        self.data_prot = data_list\n",
    "        print(count)\n",
    "\n",
    "        # data, slices = self.collate(data_list)\n",
    "        # torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len([\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')])\n",
    "\n",
    "    # file stands for file path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.data_prot[idx]\n",
    "\n",
    "    def _get_adjacency(self, file):\n",
    "        edge_ind = []\n",
    "        molecule = bg.Pmolecule(file)\n",
    "        network = molecule.network()\n",
    "        mat = nx.adjacency_matrix(network)\n",
    "        m = mat.todense()\n",
    "        return m\n",
    "\n",
    "    # get adjacency matrix in coo format to pass in GCNN model\n",
    "\n",
    "    def _get_edgeindex(self, file, adjacency_mat):\n",
    "        edge_ind = []\n",
    "        m = self._get_adjacency(file)\n",
    "        # check_symmetric(m, rtol=1e-05, atol=1e-08)\n",
    "\n",
    "        a = np.nonzero(m > 0)[0]\n",
    "        b = np.nonzero(m > 0)[1]\n",
    "        edge_ind.append(a)\n",
    "        edge_ind.append(b)\n",
    "        return torch.tensor(np.array(edge_ind), dtype=torch.long)\n",
    "\n",
    "    # get structure from a pdb file\n",
    "    # Uses biopython\n",
    "\n",
    "    def _get_structure(self, file):\n",
    "        \"\"\"\"\n",
    "        Gets protein structure from PDB\n",
    "        input: PDB filename (i.e.: \"A0A5E8G9T8.pdb\")\n",
    "        output: PDB structure object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(id, file)\n",
    "        return structure\n",
    "\n",
    "    # Function to get sequence from pdb structure\n",
    "    # Uses structure made using biopython\n",
    "    # Those residues for which symbols are U / X are converted into A\n",
    "\n",
    "    def _get_sequence(self, structure):\n",
    "        sequence = \"\"\n",
    "        for model in structure:\n",
    "          for chain in model:\n",
    "            for residue in chain:\n",
    "              if residue.get_resname() in ressymbl.keys():\n",
    "                  sequence = sequence + ressymbl[residue.get_resname()]\n",
    "        return sequence\n",
    "\n",
    "    # One hot encoding for symbols\n",
    "\n",
    "    def _get_one_hot_symbftrs(self, sequence):\n",
    "        one_hot_symb = np.zeros((len(sequence), len(pro_res_table)))\n",
    "        row = 0\n",
    "        for res in sequence:\n",
    "          col = pro_res_table.index(res)\n",
    "          one_hot_symb[row][col] = 1\n",
    "          row += 1\n",
    "        return torch.tensor(one_hot_symb, dtype=torch.float)\n",
    "\n",
    "    # Residue features calculated from pcp_dict\n",
    "\n",
    "    def _get_res_ftrs(self, sequence):\n",
    "        res_ftrs_out = []\n",
    "        for res in sequence:\n",
    "          res_ftrs_out.append(pcp_dict[res])\n",
    "        res_ftrs_out = np.array(res_ftrs_out)\n",
    "        # print(res_ftrs_out.shape)\n",
    "        return torch.tensor(res_ftrs_out, dtype=torch.float)\n",
    "\n",
    "    # total features after concatenating one_hot_symbftrs and res_ftrs\n",
    "\n",
    "    def _get_node_ftrs(self, sequence):\n",
    "        one_hot_symb = one_hot_symbftrs(sequence)\n",
    "        res_ftrs_out = res_ftrs(sequence)\n",
    "        return torch.tensor(np.hstack((one_hot_symb, res_ftrs_out)), dtype=torch.float)\n",
    "\n",
    "\n",
    "#prot_graphs = ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-15-032a63dd7fa3>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    try:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "#    print(np.allclose(a, a.T, rtol=rtol, atol=atol))\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "         self.root = root\n",
    "\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        raw_file_names = [str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')]\n",
    "\n",
    "        data_list = []\n",
    "        count = 0\n",
    "        for file in tqdm(raw_file_names):\n",
    "           if (pathlib.Path(file).suffix == \".pdb\"):\n",
    "            print(file)\n",
    "               try:\n",
    "                struct = self._get_structure(file)\n",
    "               except:\n",
    "                print(file)\n",
    "                continue\n",
    "               seq = self._get_sequence(struct)\n",
    "               print(seq)\n",
    "\n",
    "          # node features extracted\n",
    "               node_feats = self._get_one_hot_symbftrs(seq)\n",
    "\n",
    "          # edge-index extracted\n",
    "\n",
    "               mat = self._get_adjacency(file)\n",
    "\n",
    "           # if sequence size > matrix dimensions\n",
    "               if (mat.shape[0] < torch.Tensor.size(node_feats)[0]):\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'Mat size :{mat.shape}')\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pt')\n",
    "\n",
    "               elif mat.shape[0] == torch.Tensor.size(node_feats)[0]:\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'mat size :{mat.shape}')\n",
    "\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pdb')\n",
    "\n",
    "        self.data_prot = data_list\n",
    "        print(count)\n",
    "\n",
    "        # data, slices = self.collate(data_list)\n",
    "        # torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len([\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')])\n",
    "\n",
    "    # file stands for file path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.data_prot[idx]\n",
    "\n",
    "    def _get_adjacency(self, file):\n",
    "        edge_ind = []\n",
    "        molecule = bg.Pmolecule(file)\n",
    "        network = molecule.network()\n",
    "        mat = nx.adjacency_matrix(network)\n",
    "        m = mat.todense()\n",
    "        return m\n",
    "\n",
    "    # get adjacency matrix in coo format to pass in GCNN model\n",
    "\n",
    "    def _get_edgeindex(self, file, adjacency_mat):\n",
    "        edge_ind = []\n",
    "        m = self._get_adjacency(file)\n",
    "        # check_symmetric(m, rtol=1e-05, atol=1e-08)\n",
    "\n",
    "        a = np.nonzero(m > 0)[0]\n",
    "        b = np.nonzero(m > 0)[1]\n",
    "        edge_ind.append(a)\n",
    "        edge_ind.append(b)\n",
    "        return torch.tensor(np.array(edge_ind), dtype=torch.long)\n",
    "\n",
    "    # get structure from a pdb file\n",
    "    # Uses biopython\n",
    "\n",
    "    def _get_structure(self, file):\n",
    "        \"\"\"\"\n",
    "        Gets protein structure from PDB\n",
    "        input: PDB filename (i.e.: \"A0A5E8G9T8.pdb\")\n",
    "        output: PDB structure object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(id, file)\n",
    "        return structure\n",
    "\n",
    "    # Function to get sequence from pdb structure\n",
    "    # Uses structure made using biopython\n",
    "    # Those residues for which symbols are U / X are converted into A\n",
    "\n",
    "    def _get_sequence(self, structure):\n",
    "        sequence = \"\"\n",
    "        for model in structure:\n",
    "          for chain in model:\n",
    "            for residue in chain:\n",
    "              if residue.get_resname() in ressymbl.keys():\n",
    "                  sequence = sequence + ressymbl[residue.get_resname()]\n",
    "        return sequence\n",
    "\n",
    "    # One hot encoding for symbols\n",
    "\n",
    "    def _get_one_hot_symbftrs(self, sequence):\n",
    "        one_hot_symb = np.zeros((len(sequence), len(pro_res_table)))\n",
    "        row = 0\n",
    "        for res in sequence:\n",
    "          col = pro_res_table.index(res)\n",
    "          one_hot_symb[row][col] = 1\n",
    "          row += 1\n",
    "        return torch.tensor(one_hot_symb, dtype=torch.float)\n",
    "\n",
    "    # Residue features calculated from pcp_dict\n",
    "\n",
    "    def _get_res_ftrs(self, sequence):\n",
    "        res_ftrs_out = []\n",
    "        for res in sequence:\n",
    "          res_ftrs_out.append(pcp_dict[res])\n",
    "        res_ftrs_out = np.array(res_ftrs_out)\n",
    "        # print(res_ftrs_out.shape)\n",
    "        return torch.tensor(res_ftrs_out, dtype=torch.float)\n",
    "\n",
    "    # total features after concatenating one_hot_symbftrs and res_ftrs\n",
    "\n",
    "    def _get_node_ftrs(self, sequence):\n",
    "        one_hot_symb = one_hot_symbftrs(sequence)\n",
    "        res_ftrs_out = res_ftrs(sequence)\n",
    "        return torch.tensor(np.hstack((one_hot_symb, res_ftrs_out)), dtype=torch.float)\n",
    "\n",
    "\n",
    "#prot_graphs = ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "#    print(np.allclose(a, a.T, rtol=rtol, atol=atol))\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "         self.root = root\n",
    "\n",
    "\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        raw_file_names = [str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')]\n",
    "\n",
    "        data_list = []\n",
    "        count = 0\n",
    "        for file in tqdm(raw_file_names):\n",
    "           if (pathlib.Path(file).suffix == \".pdb\"):\n",
    "            \n",
    "               try:\n",
    "                struct = self._get_structure(file)\n",
    "                print(file)\n",
    "               except:\n",
    "                print(file)\n",
    "                continue\n",
    "               seq = self._get_sequence(struct)\n",
    "               print(seq)\n",
    "\n",
    "          # node features extracted\n",
    "               node_feats = self._get_one_hot_symbftrs(seq)\n",
    "\n",
    "          # edge-index extracted\n",
    "\n",
    "               mat = self._get_adjacency(file)\n",
    "\n",
    "           # if sequence size > matrix dimensions\n",
    "               if (mat.shape[0] < torch.Tensor.size(node_feats)[0]):\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'Mat size :{mat.shape}')\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pt')\n",
    "\n",
    "               elif mat.shape[0] == torch.Tensor.size(node_feats)[0]:\n",
    "                 edge_index = self._get_edgeindex(file, mat)\n",
    "\n",
    "                 print(f'Node features size :{torch.Tensor.size(node_feats)}')\n",
    "                 print(f'mat size :{mat.shape}')\n",
    "\n",
    "          # create data object\n",
    "                 data = Data(x=node_feats, edge_index=edge_index)\n",
    "                 count += 1\n",
    "\n",
    "                 data_list.append(data)\n",
    "                 torch.save(data, self.processed_dir + \"/\" +\n",
    "                            os.path.splitext(os.path.basename(file))[0]+'.pdb')\n",
    "\n",
    "        self.data_prot = data_list\n",
    "        print(count)\n",
    "\n",
    "        # data, slices = self.collate(data_list)\n",
    "        # torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len([\n",
    "            str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')])\n",
    "\n",
    "    # file stands for file path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.data_prot[idx]\n",
    "\n",
    "    def _get_adjacency(self, file):\n",
    "        edge_ind = []\n",
    "        molecule = bg.Pmolecule(file)\n",
    "        network = molecule.network()\n",
    "        mat = nx.adjacency_matrix(network)\n",
    "        m = mat.todense()\n",
    "        return m\n",
    "\n",
    "    # get adjacency matrix in coo format to pass in GCNN model\n",
    "\n",
    "    def _get_edgeindex(self, file, adjacency_mat):\n",
    "        edge_ind = []\n",
    "        m = self._get_adjacency(file)\n",
    "        # check_symmetric(m, rtol=1e-05, atol=1e-08)\n",
    "\n",
    "        a = np.nonzero(m > 0)[0]\n",
    "        b = np.nonzero(m > 0)[1]\n",
    "        edge_ind.append(a)\n",
    "        edge_ind.append(b)\n",
    "        return torch.tensor(np.array(edge_ind), dtype=torch.long)\n",
    "\n",
    "    # get structure from a pdb file\n",
    "    # Uses biopython\n",
    "\n",
    "    def _get_structure(self, file):\n",
    "        \"\"\"\"\n",
    "        Gets protein structure from PDB\n",
    "        input: PDB filename (i.e.: \"A0A5E8G9T8.pdb\")\n",
    "        output: PDB structure object\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure(id, file)\n",
    "        return structure\n",
    "\n",
    "    # Function to get sequence from pdb structure\n",
    "    # Uses structure made using biopython\n",
    "    # Those residues for which symbols are U / X are converted into A\n",
    "\n",
    "    def _get_sequence(self, structure):\n",
    "        sequence = \"\"\n",
    "        for model in structure:\n",
    "          for chain in model:\n",
    "            for residue in chain:\n",
    "              if residue.get_resname() in ressymbl.keys():\n",
    "                  sequence = sequence + ressymbl[residue.get_resname()]\n",
    "        return sequence\n",
    "\n",
    "    # One hot encoding for symbols\n",
    "\n",
    "    def _get_one_hot_symbftrs(self, sequence):\n",
    "        one_hot_symb = np.zeros((len(sequence), len(pro_res_table)))\n",
    "        row = 0\n",
    "        for res in sequence:\n",
    "          col = pro_res_table.index(res)\n",
    "          one_hot_symb[row][col] = 1\n",
    "          row += 1\n",
    "        return torch.tensor(one_hot_symb, dtype=torch.float)\n",
    "\n",
    "    # Residue features calculated from pcp_dict\n",
    "\n",
    "    def _get_res_ftrs(self, sequence):\n",
    "        res_ftrs_out = []\n",
    "        for res in sequence:\n",
    "          res_ftrs_out.append(pcp_dict[res])\n",
    "        res_ftrs_out = np.array(res_ftrs_out)\n",
    "        # print(res_ftrs_out.shape)\n",
    "        return torch.tensor(res_ftrs_out, dtype=torch.float)\n",
    "\n",
    "    # total features after concatenating one_hot_symbftrs and res_ftrs\n",
    "\n",
    "    def _get_node_ftrs(self, sequence):\n",
    "        one_hot_symb = one_hot_symbftrs(sequence)\n",
    "        res_ftrs_out = res_ftrs(sequence)\n",
    "        return torch.tensor(np.hstack((one_hot_symb, res_ftrs_out)), dtype=torch.float)\n",
    "\n",
    "\n",
    "#prot_graphs = ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/formatters.py\", line 223, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/formatters.py\", line 708, in __call__\n",
      "    printer.pretty(obj)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/lib/pretty.py\", line 410, in pretty\n",
      "    return _repr_pprint(obj, self, cycle)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/lib/pretty.py\", line 778, in _repr_pprint\n",
      "    output = repr(obj)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/torch_geometric/data/dataset.py\", line 362, in __repr__\n",
      "    arg_repr = str(len(self)) if len(self) > 1 else ''\n",
      "  File \"<ipython-input-16-6d2f876e967b>\", line 71, in __len__\n",
      "    str(self.root)+f for f in os.listdir(self.root) if not f.startswith('.')])\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './d/'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1005, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "ProteinDataset(\"./d/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-18-b0158f806fd2>\", line 1, in <module>\n",
      "    raw_file_names = [str(root)+f for f in os.listdir(root) if not f.startswith('.')]\n",
      "NameError: name 'root' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1005, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "        raw_file_names = [str(root)+f for f in os.listdir(root) if not f.startswith('.')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"./d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-20-b0158f806fd2>\", line 1, in <module>\n",
      "    raw_file_names = [str(root)+f for f in os.listdir(root) if not f.startswith('.')]\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './d/'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1005, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/Users/nguyjust/opt/anaconda3/envs/py9/lib/python3.9/site-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "        raw_file_names = [str(root)+f for f in os.listdir(root) if not f.startswith('.')]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
